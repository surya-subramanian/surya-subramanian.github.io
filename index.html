<!doctype html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>surya subramanian </title>
    <style>
        body {
            font-family: serif;
            color: black;
            background-color: white;
            max-width: 800px;
            margin: 40px auto;
            padding: 0 20px;
            line-height: 1.6;
        }
        h1 {
            font-size: 2.5em;
            margin-bottom: 0.5em;
        }
        h2 {
            font-size: 1.8em;
            margin-top: 1.5em;
            margin-bottom: 0.5em;
        }
        p {
            margin-bottom: 1em;
        }
        ul {
            list-style-type: disc;
            margin-bottom: 1em;
        }
        ul li {
            margin-bottom: 0.5em;
        }
        a {
            color: blue;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
    </style>
</head>
<body>

    <h1>surya subramanian (website still a work in progress)</h1>
    <p>some things about me:</p>
    <ul>
        <li>born and raised in the bay area</li>
        <li>currently in atlanta - third-year undergraduate studying cs at georgia tech.</li>
        <li>i love weight-lifting, hanging out with my friends, going to expensive restaurants, trying out different caffes + coffee, cooking, and watching football and basketball in my spare time</li>
    </ul>

    <h2>my interests</h2>
    <p>my interests lie in the intersection of machine learning and systems. i'm passionate about ml training infrastructure, compilers, inference, distributed systems, and high performance computing for agi.</p>

    <p>i'm really interested in the entire ml acceleration stack â€“ from large-scale distributed training and model parallelism to efficient inference at scale. i am particularly fascinated by scaling transformer architectures and various inference optimizations. these include kernel-level gpu acceleration, efficient attention mechanisms, accelerated decoding methods, and model compression techniques. </p>
    
    <h2>a little about me</h2>
    <p>previously, i created a data acquisition -> feature embedding pipeline for downstream ml models (conversion user match prediction, ads ranking + retrieval, <a href="https://medium.com/pinterest-engineering/linksage-gnn-based-pinterest-off-site-content-understanding-fca14b0d1141">linksage</a>, etc.) at pinterest .</p>
    <p>i am currently pursuing research in efficient inference optimizations for mixture-of-expert models and improving reasoning in llms.</p>
    
    <p>i've also pursued several independent projects in this space:</p>
    <ul>
        <li>an efficient paligemma vision language model inference pipeline with cpu and mps quantization and memory optimizations</li>
        <li>high-performance diffusion transformer model using cuda/c++ with matrix multiplication kernel optimizations</li>
        <li>implementing distributed training from scratch for transformers with support for fsdp, ddp and checkpointing/gradient accumulation</li>
    </ul>

   <h2>some thoughts</h2>
<ul>
    <li>through hard work, determination, and a little bit of luck, you can reshape the universe to your preferences. it is inspiring that you have the power to write your own destiny!</li>
    <li>genuine passion and enthusiasm matter. every good thing is a product of someone's obsession.</li>
    <li>one of the most rewarding things you can do is find someone you look up to, in any aspect of life, and learn from them.</li>
</ul>

</body>
</html>
